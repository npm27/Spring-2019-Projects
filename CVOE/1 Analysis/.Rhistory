install.packages("memisc")
install.packages(ez)
install.packages("ez")
install.packages("forestplot")
install.packages("devtools")
install.packages("psych")
install.packages("lme4")
install.packages("glmer")
install.packages(Glmr)
install.packages("lmer")
install.packages("moments")
install.packages("reshape")
install.packages("ggplot2")
install.packages("lavaan")
install.packages("SemPlot")
install.packages("semPlot")
install.packages("devtools")
library(devtools)
devtools::install_github("crsh/papaja")
800+730+730
2260-590-150-200-100-25-50-100
setwd("~/GitHub/Spring-2019-Projects/Direction JOL/Delayed JOL")
##set up
dat = read.csv("output 2_14 final.csv")
library(ggplot2)
library(reshape)
##put recall on correct scale
dat$Scored_Response = (dat$Scored_Response * 100)
##make jol score numeric
dat$Jol_Response = as.numeric(dat$Jol_Response)
##make 101's = 100
dat$Jol_Response[dat$Jol_Response > "100"] = NA
##get sample size
summary(dat$Subject) #n = 18
##remove missing
nomissing = na.omit(dat)
##get descriptives
tapply(nomissing$Jol_Response,
nomissing$Direction, mean)
tapply(nomissing$Jol_Response,
nomissing$Direction, sd)
tapply(nomissing$Scored_Response,
nomissing$Direction, mean)
tapply(nomissing$Scored_Response,
nomissing$Direction, sd)
####make the graph####
nomiss = na.omit(long.dat)
##melt the data
long.dat = melt(dat, id = c("Subject", "Block",
"ListNum", "Direction", "ExperimentName", "cue_target",
"recall_response", "cue_prompt"))
summary(long.dat)
colnames(long.dat)[9] = "Task"
colnames(long.dat)[10] = "Score"
cleanup = theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
axis.line = element_line(colour = "black"),
legend.key = element_rect(fill = "white"),
text = element_text(size = 15))
bar1 = ggplot(nomiss, aes(Direction, Score, fill = Task))
bar1 = bar1 +
stat_summary(fun.y = mean,
geom = "bar",
position = "dodge",
color = "Black") +
stat_summary(fun.data = mean_cl_normal,
geom = "errorbar",
position = position_dodge(width = 0.90),
width = 0.2,
color = "black") +
scale_fill_manual("Task",
values = c("Jol_Response" = "indianred4",
"Scored_Response" = "dimgray")) +
cleanup +
xlab("Direction") +
ylab("Mean Task Performance") +
#ylim(0,100) +
labs(title="All Blocks")
bar1
setwd("~/GitHub/Spring-2019-Projects/Direction JOL/Output/Merged")
##set up
dat = read.csv("output 2_14 final.csv")
library(ggplot2)
library(reshape)
##put recall on correct scale
dat$Scored_Response = (dat$Scored_Response * 100)
##make jol score numeric
dat$Jol_Response = as.numeric(dat$Jol_Response)
##make 101's = 100
dat$Jol_Response[dat$Jol_Response > "100"] = NA
##get sample size
summary(dat$Subject) #n = 18
##remove missing
nomissing = na.omit(dat)
##get descriptives
tapply(nomissing$Jol_Response,
nomissing$Direction, mean)
tapply(nomissing$Jol_Response,
nomissing$Direction, sd)
tapply(nomissing$Scored_Response,
nomissing$Direction, mean)
tapply(nomissing$Scored_Response,
nomissing$Direction, sd)
####make the graph####
nomiss = na.omit(long.dat)
##melt the data
long.dat = melt(dat, id = c("Subject", "Block",
"ListNum", "Direction", "ExperimentName", "cue_target",
"recall_response", "cue_prompt"))
summary(long.dat)
colnames(long.dat)[9] = "Task"
colnames(long.dat)[10] = "Score"
cleanup = theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
axis.line = element_line(colour = "black"),
legend.key = element_rect(fill = "white"),
text = element_text(size = 15))
bar1 = ggplot(nomiss, aes(Direction, Score, fill = Task))
bar1 = bar1 +
stat_summary(fun.y = mean,
geom = "bar",
position = "dodge",
color = "Black") +
stat_summary(fun.data = mean_cl_normal,
geom = "errorbar",
position = position_dodge(width = 0.90),
width = 0.2,
color = "black") +
scale_fill_manual("Task",
values = c("Jol_Response" = "indianred4",
"Scored_Response" = "dimgray")) +
cleanup +
xlab("Direction") +
ylab("Mean Task Performance") +
#ylim(0,100) +
labs(title="All Blocks")
bar1
bar1
##set up
dat = read.csv("output 2_14 final.csv")
library(ggplot2)
library(reshape)
##put recall on correct scale
dat$Scored_Response = (dat$Scored_Response * 100)
##make jol score numeric
dat$Jol_Response = as.numeric(dat$Jol_Response)
##make 101's = 100
dat$Jol_Response[dat$Jol_Response > "100"] = NA
##get sample size
summary(dat$Subject) #n = 18
##remove missing
nomissing = na.omit(dat)
##get descriptives
tapply(nomissing$Jol_Response,
nomissing$Direction, mean)
tapply(nomissing$Jol_Response,
nomissing$Direction, sd)
tapply(nomissing$Scored_Response,
nomissing$Direction, mean)
tapply(nomissing$Scored_Response,
nomissing$Direction, sd)
####make the graph####
nomiss = na.omit(long.dat)
##melt the data
long.dat = melt(dat, id = c("Subject", "Block",
"ListNum", "Direction", "ExperimentName", "cue_target",
"recall_response", "cue_prompt"))
summary(long.dat)
colnames(long.dat)[9] = "Task"
colnames(long.dat)[10] = "Score"
cleanup = theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
axis.line = element_line(colour = "black"),
legend.key = element_rect(fill = "white"),
text = element_text(size = 15))
bar1 = ggplot(nomiss, aes(Direction, Score, fill = Task))
bar1 = bar1 +
stat_summary(fun.y = mean,
geom = "bar",
position = "dodge",
color = "Black") +
stat_summary(fun.data = mean_cl_normal,
geom = "errorbar",
position = position_dodge(width = 0.90),
width = 0.2,
color = "black") +
scale_fill_manual("Task",
values = c("Jol_Response" = "indianred4",
"Scored_Response" = "dimgray")) +
cleanup +
xlab("Direction") +
ylab("Mean Task Performance") +
#ylim(0,100) +
labs(title="All Blocks")
bar1
####make the graph####
nomiss = na.omit(long.dat)
bar1 = ggplot(nomiss, aes(Direction, Score, fill = Task))
bar1 = bar1 +
stat_summary(fun.y = mean,
geom = "bar",
position = "dodge",
color = "Black") +
stat_summary(fun.data = mean_cl_normal,
geom = "errorbar",
position = position_dodge(width = 0.90),
width = 0.2,
color = "black") +
scale_fill_manual("Task",
values = c("Jol_Response" = "indianred4",
"Scored_Response" = "dimgray")) +
cleanup +
xlab("Direction") +
ylab("Mean Task Performance") +
#ylim(0,100) +
labs(title="All Blocks")
bar1
##set up
dat = read.csv("output 2_14 final.csv")
library(ggplot2)
library(reshape)
##put recall on correct scale
dat$Scored_Response = (dat$Scored_Response * 100)
##make jol score numeric
dat$Jol_Response = as.numeric(dat$Jol_Response)
##make 101's = 100
dat$Jol_Response[dat$Jol_Response > "100"] = NA
##get sample size
summary(dat$Subject) #n = 18
##remove missing
nomissing = na.omit(dat)
##get descriptives
tapply(nomissing$Jol_Response,
nomissing$Direction, mean)
tapply(nomissing$Jol_Response,
nomissing$Direction, sd)
tapply(nomissing$Scored_Response,
nomissing$Direction, mean)
tapply(nomissing$Scored_Response,
nomissing$Direction, sd)
####make the graph####
nomiss = na.omit(long.dat)
##melt the data
long.dat = melt(dat, id = c("Subject", "Block",
"ListNum", "Direction", "ExperimentName", "cue_target",
"recall_response", "cue_prompt"))
summary(long.dat)
colnames(long.dat)[9] = "Task"
colnames(long.dat)[10] = "Score"
cleanup = theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
axis.line = element_line(colour = "black"),
legend.key = element_rect(fill = "white"),
text = element_text(size = 15))
bar1 = ggplot(nomiss, aes(Direction, Score, fill = Task))
bar1 = bar1 +
stat_summary(fun.y = mean,
geom = "bar",
position = "dodge",
color = "Black") +
stat_summary(fun.data = mean_cl_normal,
geom = "errorbar",
position = position_dodge(width = 0.90),
width = 0.2,
color = "black") +
scale_fill_manual("Task",
values = c("Jol_Response" = "indianred4",
"Scored_Response" = "dimgray")) +
cleanup +
xlab("Direction") +
ylab("Mean Task Performance") +
ylim(0,100) +
labs(title="All Blocks")
bar1
tapply(nomissing$Scored_Response,
nomissing$Direction, mean)
setwd("~/GitHub/Spring-2019-Projects/CVOE/0 Output/2 Processed")
##setup
#dat = read.csv("CVOE Scored.csv")
dat = read.csv("CVOE 2_27_19.csv")
##setup
#dat = read.csv("CVOE Scored.csv")
dat = read.csv("CVOE 2_27_19.csv")
View(dat)
#dat = dat[ , -c(13, 15:16)]
dat = dat[ , -13]
##does response match key?
dat$Match = dat$Response == dat$KEY
dat$score = as.numeric(dat$Match)
#dat = dat[ , -c(13, 15:16)]
dat = dat[ , -13]
##does response match key?
dat$Match = dat$Response == dat$Key
##setup
#dat = read.csv("CVOE Scored.csv")
dat = read.csv("CVOE 2_27_19.csv")
#dat = dat[ , -c(13, 15:16)]
dat = dat[ , -13]
##does response match key?
dat$Match = dat$Response == dat$Key
dat$score = as.numeric(dat$Match)
write.csv(dat, file = "CVOE_Final 2_27_19.csv")
##setup
#dat = read.csv("CVOE Scored.csv")
dat = read.csv("CVOE 2_27_19.csv")
##setup
#dat = read.csv("CVOE Scored.csv")
dat = read.csv("CVOE 2_27_19.csv")
#dat = dat[ , -c(13, 15:16)]
#dat = dat[ , -13]
##does response match key?
dat$Match = dat$Response == dat$Key
dat$score = as.numeric(dat$Match)
write.csv(dat, file = "CVOE_Final 2_27_19.csv")
setwd("~/GitHub/Spring-2019-Projects/CVOE/1 Analysis")
dat = read.csv("CVOE_Final Output.csv")
View(dat)
CVOE_A = subset(dat,
dat$ExperimentName == "CVOE Updated")
CVOE_A = subset(dat,
dat$ExperimentName == "CVOE updated")
summary(dat$ExperimentName)
CVOE_B = subset(dat,
dat$ExperimentName == "CVOE_B")
CVOE_C = subset(dat,
dat$ExperimentName == "CVOE_C")
CVOE_D = subset(dat,
dat$ExperimentName == "CVOE_D")
task_listA = c("cv", "oe", "alt", "shuf")
task_listB = c("oe", "cv", "shuf", "alt")
task_listC = c("oe", "cv", "alt", "shuf")
task_listD = c("cv", "oe", "shuf", "alt")
rep_list = c(96, 96, 120, 120)
CVOE_A$block_type = rep(task_listA, rep_list)
CVOE_B$block_type = rep(task_listB, rep_list)
CVOE_C$block_type = rep(task_listC, rep_list)
CVOE_D$block_type = rep(task_listD, rep_list)
##put it all back together
combined = rbind(CVOE_A, CVOE_B, CVOE_C, CVOE_D)
####check descriptives####
##mean rts by group
tapply(combined$RT,
combined$block_type, mean)
##mean percent correct by group
tapply(combined$score * 100,
combined$block_type, mean)
##differences within switch groups
##make a switch group subset
yes.switch = subset(combined,
combined$Switch == "Y")
no.switch = subset(combined,
combined$Switch == "N")
tapply(yes.switch$RT,
yes.switch$block_type, mean)
tapply(no.switch$RT,
no.switch$block_type, mean)
tapply(yes.switch$score * 100,
yes.switch$block_type, mean)
tapply(no.switch$score * 100,
no.switch$block_type, mean)
##congruency
tapply(combined$RT,
list(combined$block_type, combined$Congruent), mean)
tapply(combined$score,
list(combined$block_type, combined$Congruent), mean)
##check by subject
tapply(combined$score,
list(combined$block_type, combined$Subject), mean)
tapply(combined$RT,
list(combined$block_type, combined$Subject), mean)
